<h2>1、使用 conda 先构建一个 Python-3.10 的虚拟环境，再安装 XTuner</h2> <br><pre><code>cd ~<br>#git clone 本repo<br>git clone https://github.com/InternLM/Tutorial.git -b camp4<br>mkdir -p /root/finetune && cd /root/finetune<br>conda create -n xtuner-env python=3.10 -y<br>conda activate xtuner-env<br><br><br>cd /root/Tutorial/docs/L1/XTuner<br>pip install -r requirements.txt</code></pre> <br><h2>2、创建一个新的文件夹用于存储微调数据</h2> <br><pre><code>mkdir -p /root/finetune/data && cd /root/finetune/data<br>cp -r /root/Tutorial/data/assistant_Tuner.jsonl  /root/finetune/data</code></pre> <br><h2>3、在当前目录下创建一个 <code>change_script.py</code> 文件</h2> <br><p>        内容如下：</p> <br><pre><code># 创建 `change_script.py` 文件<br>touch /root/finetune/data/change_script.py<br><br>#输入文件内容<br>import json<br>import argparse<br>from tqdm import tqdm<br><br>def process_line(line, old_text, new_text):<br>    # 解析 JSON 行<br>    data = json.loads(line)<br>    <br>    # 递归函数来处理嵌套的字典和列表<br>    def replace_text(obj):<br>        if isinstance(obj, dict):<br>            return {k: replace_text(v) for k, v in obj.items()}<br>        elif isinstance(obj, list):<br>            return [replace_text(item) for item in obj]<br>        elif isinstance(obj, str):<br>            return obj.replace(old_text, new_text)<br>        else:<br>            return obj<br>    <br>    # 处理整个 JSON 对象<br>    processed_data = replace_text(data)<br>    <br>    # 将处理后的对象转回 JSON 字符串<br>    return json.dumps(processed_data, ensure_ascii=False)<br><br>def main(input_file, output_file, old_text, new_text):<br>    with open(input_file, 'r', encoding='utf-8') as infile, \<br>         open(output_file, 'w', encoding='utf-8') as outfile:<br>        <br>        # 计算总行数用于进度条<br>        total_lines = sum(1 for _ in infile)<br>        infile.seek(0)  # 重置文件指针到开头<br>        <br>        # 使用 tqdm 创建进度条<br>        for line in tqdm(infile, total=total_lines, desc="Processing"):<br>            processed_line = process_line(line.strip(), old_text, new_text)<br>            outfile.write(processed_line + '\n')<br><br>if __name__ == "__main__":<br>    parser = argparse.ArgumentParser(description="Replace text in a JSONL file.")<br>    parser.add_argument("input_file", help="Input JSONL file to process")<br>    parser.add_argument("output_file", help="Output file for processed JSONL")<br>    parser.add_argument("--old_text", default="尖米", help="Text to be replaced")<br>    parser.add_argument("--new_text", default="闻星", help="Text to replace with")<br>    args = parser.parse_args()<br><br>    main(args.input_file, args.output_file, args.old_text, args.new_text)</code></pre> <br><p>        注意这里自定义名字：</p> <br><p style="text-align:center"><img alt="" src="https://i-blog.csdnimg.cn/direct/38493872da004fe99a1173b0290da64d.bmp" /></p> <br><p>        执行脚本</p> <br><pre><code># usage：python change_script.py {input_file.jsonl} {output_file.jsonl}<br>cd ~/finetune/data<br>python change_script.py ./assistant_Tuner.jsonl ./assistant_Tuner_change.jsonl</code></pre> <br><p>        查看数据</p> <br><h2>4、训练启动</h2> <br><p>        复制模型</p> <br><pre><code>mkdir /root/finetune/models<br><br>ln -s /root/share/new_models/Shanghai_AI_Laboratory/internlm2_5-7b-chat /root/finetune/models/internlm2_5-7b-chat</code></pre> <br><p>         修改 Config</p> <br><pre><code># cd {path/to/finetune}<br>cd /root/finetune<br>mkdir ./config<br>cd config<br>xtuner copy-cfg internlm2_5_chat_7b_qlora_alpaca_e3 ./</code></pre> <br><p style="text-align:center"><img alt="" src="https://i-blog.csdnimg.cn/direct/227358fe502f485f839d880f8bae1841.bmp" /></p> <br><p>        启动微调</p> <br><pre><code>cd /root/finetune<br>conda activate xtuner-env<br><br>xtuner train ./config/internlm2_5_chat_7b_qlora_alpaca_e3_copy.py --deepspeed deepspeed_zero2 --work-dir ./work_dirs/assistTuner</code></pre> <br><p>        权重转换</p> <br><pre><code>cd /root/finetune/work_dirs/assistTuner<br><br>conda activate xtuner-env<br><br># 先获取最后保存的一个pth文件<br>pth_file=`ls -t /root/finetune/work_dirs/assistTuner/*.pth | head -n 1 | sed 's/:$//'`<br>export MKL_SERVICE_FORCE_INTEL=1<br>export MKL_THREADING_LAYER=GNU<br>xtuner convert pth_to_hf ./internlm2_5_chat_7b_qlora_alpaca_e3_copy.py ${pth_file} ./hf</code></pre> <br><p>         模型合并</p> <br><pre><code>cd /root/finetune/work_dirs/assistTuner<br>conda activate xtuner-env<br><br>export MKL_SERVICE_FORCE_INTEL=1<br>export MKL_THREADING_LAYER=GNU<br>xtuner convert merge /root/finetune/models/internlm2_5-7b-chat ./hf ./merged --max-shard-size 2GB</code></pre> <br><p>         模型合并完成后，目录结构应该是这样子的：</p> <br><p style="text-align:center"><img alt="" src="https://i-blog.csdnimg.cn/direct/5a4932998ae64ee0bf02de92792cb18a.bmp" /></p> <br><h2>5、模型 WebUI 对话</h2> <br><p>        路径修改为微调后的模型的路径</p> <br><pre><code>cd ~/Tutorial/tools/L1_XTuner_code</code></pre> <br><p>         修改 <code>xtuner_streamlit_demo.py</code> 脚本</p> <br><pre><code class="hljs"># 直接修改脚本文件第18行<br>- model_name_or_path = "Shanghai_AI_Laboratory/internlm2_5-7b-chat"<br>+ model_name_or_path = "/root/finetune/work_dirs/assistTuner/merged"</code></pre> <br><p>        直接启动应用</p> <br><pre><code class="hljs">conda activate xtuner-env<br><br>pip install streamlit==1.31.0<br>streamlit run /root/Tutorial/tools/L1_XTuner_code/xtuner_streamlit_demo.py</code></pre> <br><p>        运行后，确保本机端口映射正常</p> <br><pre><code class="hljs">ssh -CNg -L 8501:127.0.0.1:8501 root@ssh.intern-ai.org.cn -p *****</code></pre> <br><p style="text-align:center"><img alt="" src="https://i-blog.csdnimg.cn/direct/650da73e69d74e299e2514e2952f37a2.bmp" /></p> <br><p><img alt="" src="https://i-blog.csdnimg.cn/direct/3ce9317e06e84239bdb1ec9a30ea7cb6.bmp" /></p> <br><p>        最后，通过浏览器访问：<a href="http://127.0.0.1:8501/" rel="nofollow" title="http://127.0.0.1:8501">http://127.0.0.1:8501</a> 来进行对话:</p> <br><p style="text-align:center"><img alt="" src="https://i-blog.csdnimg.cn/direct/c21fbf3370e64de89bc7e7987943abba.png" /> </p>