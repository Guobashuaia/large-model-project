<h2>1、任务</h2> <br><p>        基于 LlamaIndex 构建自己的 RAG 知识库，寻找一个问题 A 在使用 LlamaIndex 之前 浦语 API 不会回答，借助 LlamaIndex 后 浦语 API 具备回答 A 的能力，截图保存。</p> <br><h2>2、环境、模型准备</h2> <br><h3>2.1、基础环境</h3> <br><p>        首先，打开 <code>Intern Studio</code> 界面，进入开发机后，创建新的conda环境，命名为 <code>llamaindex</code>，在命令行模式下运行：</p> <br><pre><code>conda create -n llamaindex python=3.10</code></pre> <br><p>        运行 <code>conda</code> 命令，激活 <code>llamaindex</code> 然后安装相关基础依赖 python 虚拟环境:</p> <br><pre><code>conda activate llamaindex<br><br>pip install einops==0.7.0 protobuf==5.26.1</code></pre> <br><p>        安装 Llamaindex和相关的包</p> <br><pre><code>conda activate llamaindex<br>pip install llama-index==0.11.20<br>pip install llama-index-llms-replicate==0.3.0<br>pip install llama-index-llms-openai-like==0.2.0<br>pip install llama-index-embeddings-huggingface==0.3.1<br>pip install llama-index-embeddings-instructor==0.2.1<br>pip install torch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 --index-url https://download.pytorch.org/whl/cu121</code></pre> <br><h3>  2.2、下载 Sentence Transformer 模型</h3> <br><p>        <span style="background-color:#ffffff"><span style="color:#1f2328">源词向量模型 Sentence Transformer:</span></span></p> <br><pre><code>cd ~<br>mkdir llamaindex_demo<br>mkdir model<br>cd ~/llamaindex_demo<br>touch download_hf.py</code></pre> <br><p>        打开<code>download_hf.py</code> 贴入以下代码：</p> <br><pre><code>import os<br><br># 设置环境变量<br>os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'<br><br># 下载模型<br>os.system('huggingface-cli download --resume-download sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 --local-dir /root/model/sentence-transformer')</code></pre> <br><p>        在 /root/llamaindex_demo 目录下执行该脚本：</p> <br><pre><code>cd /root/llamaindex_demo<br>conda activate llamaindex<br>python download_hf.py</code></pre> <br><h3>2.3、下载 NLTK 相关资源</h3> <br><p>        从国内仓库镜像地址下载相关资源，保存到服务器上</p> <br><pre><code>cd /root<br>git clone https://gitee.com/yzy0612/nltk_data.git  --branch gh-pages<br>cd nltk_data<br>mv packages/*  ./<br>cd tokenizers<br>unzip punkt.zip<br>cd ../taggers<br>unzip averaged_perceptron_tagger.zip</code></pre> <br><h2>3、是否使用 LlamaIndex 前后对比</h2> <br><h3>3.1、不使用 LlamaIndex RAG（仅API）</h3> <br><p>        新建一个python文件：</p> <br><pre><code>cd ~/llamaindex_demo<br>touch test_internlm.py</code></pre> <br><p>        打开test_internlm.py 贴入以下代码：</p> <br><pre><code>from openai import OpenAI<br><br>base_url = "https://internlm-chat.intern-ai.org.cn/puyu/api/v1/"<br>api_key = "sk-请填写准确的 token！"<br>model="internlm2.5-latest"<br><br># base_url = "https://api.siliconflow.cn/v1"<br># api_key = "sk-请填写准确的 token！"<br># model="internlm/internlm2_5-7b-chat"<br><br>client = OpenAI(<br>    api_key=api_key , <br>    base_url=base_url,<br>)<br><br>chat_rsp = client.chat.completions.create(<br>    model=model,<br>    messages=[{"role": "user", "content": "xtuner是什么？"}],<br>)<br><br>for choice in chat_rsp.choices:<br>    print(choice.message.content)</code></pre> <br><p>        这里我换了一个问题（API已经被改过，是无效的），如下图：</p> <br><p style="text-align:center"><img alt="" src="https://i-blog.csdnimg.cn/direct/6474ae791972424882928c01084bd84e.png" /></p> <br><p>        之后运行：</p> <br><pre><code class="hljs">conda activate llamaindex<br>cd ~/llamaindex_demo/<br>python test_internlm.py</code></pre> <br><p>        结果如下（AI不知道哪吒2，就只说哪吒1）： </p> <br><p style="text-align:center"><img alt="" src="https://i-blog.csdnimg.cn/direct/0f0c4892e13d4619b37438c7ed11f4a3.bmp" /></p> <br><h3> 3.2、使用 API+LlamaIndex</h3> <br><p>         运行以下命令，获取知识库（我这边直接找了个关于哪吒2网页信息并放入data目录下nezha2_info.txt中）</p> <br><pre><code class="hljs">conda activate llamaindex<br><br><br>cd ~/llamaindex_demo<br>mkdir data<br>cd data<br>git clone https://github.com/InternLM/xtuner.git<br>mv xtuner/README_zh-CN.md ./</code></pre> <br><p style="text-align:center"><img alt="" src="https://i-blog.csdnimg.cn/direct/97902f22504446509bf7e756be1234f9.bmp" /> </p> <br><p>        运行以下指令，新建一个python文件：</p> <br><pre><code class="hljs">cd ~/llamaindex_demo<br>touch llamaindex_RAG.py</code></pre> <br><p>        打开<code>llamaindex_RAG.py</code>贴入以下代码</p> <br><pre><code class="hljs">import os <br>os.environ['NLTK_DATA'] = '/root/nltk_data'<br><br>from llama_index.core import VectorStoreIndex, SimpleDirectoryReader<br>from llama_index.core.settings import Settings<br>from llama_index.embeddings.huggingface import HuggingFaceEmbedding<br>from llama_index.legacy.callbacks import CallbackManager<br>from llama_index.llms.openai_like import OpenAILike<br><br><br># Create an instance of CallbackManager<br>callback_manager = CallbackManager()<br><br>api_base_url =  "https://internlm-chat.intern-ai.org.cn/puyu/api/v1/"<br>model = "internlm2.5-latest"<br>api_key = "请填写 API Key"<br><br># api_base_url =  "https://api.siliconflow.cn/v1"<br># model = "internlm/internlm2_5-7b-chat"<br># api_key = "请填写 API Key"<br><br><br><br>llm =OpenAILike(model=model, api_base=api_base_url, api_key=api_key, is_chat_model=True,callback_manager=callback_manager)<br><br><br>#初始化一个HuggingFaceEmbedding对象，用于将文本转换为向量表示<br>embed_model = HuggingFaceEmbedding(<br>#指定了一个预训练的sentence-transformer模型的路径<br>    model_name="/root/model/sentence-transformer"<br>)<br>#将创建的嵌入模型赋值给全局设置的embed_model属性，<br>#这样在后续的索引构建过程中就会使用这个模型。<br>Settings.embed_model = embed_model<br><br>#初始化llm<br>Settings.llm = llm<br><br>#从指定目录读取所有文档，并加载数据到内存中<br>documents = SimpleDirectoryReader("/root/llamaindex_demo/data").load_data()<br>#创建一个VectorStoreIndex，并使用之前加载的文档来构建索引。<br># 此索引将文档转换为向量，并存储这些向量以便于快速检索。<br>index = VectorStoreIndex.from_documents(documents)<br># 创建一个查询引擎，这个引擎可以接收查询并返回相关文档的响应。<br>query_engine = index.as_query_engine()<br>response = query_engine.query("xtuner是什么?")<br><br>print(response)</code></pre> <br><p>       我同样将问题修改为（“哪吒2是什么？”）</p> <br><p><img alt="" src="https://i-blog.csdnimg.cn/direct/273ba0fd8c0b4af7ab3a2f860d8b7d39.bmp" /></p> <br><p>        再运行：</p> <br><pre><code class="hljs">conda activate llamaindex<br>cd ~/llamaindex_demo/<br>python llamaindex_RAG.py</code></pre> <br><p>        结果为：</p> <br><p style="text-align:center"><img alt="" src="https://i-blog.csdnimg.cn/direct/d89b36f8b8ee46a5868375eabfe8ef30.bmp" /></p>